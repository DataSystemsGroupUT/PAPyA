{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a library to find the best performing configuration from a set of dimensions (i.e. schemas, partition, storage) which can be specified inside the <b>settings.yaml</b> file in the resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PAPyA==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the configuration file and log files location for the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Configurations for SP2Bench Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_sp2bench = \"settings.yaml\" # config file location\n",
    "logs_sp2bench = \"log\" # logs file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Configurations for Watdiv Data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_watdiv = \"settings_watdiv.yaml\" # config file location\n",
    "logs_watdiv = \"log_watdiv\" # logs file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Configuration file</u> <br>\n",
    "The configuration file is a yaml data-serialization language which has two main parts, the dimensions and the number of query experiments. You can add more dimensions here or change these existing dimensions to anything you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Example :</i> \n",
    "```yaml\n",
    "dimensions:\n",
    "    schemas: [\"st\", \"vt\", \"pt\", \"extvt\", \"wpt\"]\n",
    "    partition: [\"horizontal\", \"predicate\", \"subject\"]\n",
    "    storage: [\"csv\", \"avro\", \"parquet\", \"orc\"]\n",
    "\n",
    "query: 11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Log file structure</u> <br>\n",
    "the structure of the log files must follow the order of dimensions in the configuration file (i.e. {schemas}.{partition}.{storage}.txt) and the subfolders should be the ranking sets of the experiments (i.e. dataset sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Example :</i>\n",
    "```\n",
    "UI Module\n",
    "└───log\n",
    "    │\n",
    "    |───100M\n",
    "    |    │   st.horizontal.csv.txt\n",
    "    |    │   st.horizontal.avro.txt\n",
    "    |    │   ...\n",
    "    │\n",
    "    └───250M\n",
    "        |   st.horizontal.csv.txt\n",
    "        │   st.horizontal.avro.txt\n",
    "        │   ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Dimensional Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SDRank</b> is a class module from PAPyA library to calculate ranking score _R_ for each dimension independently that operates over a log-based structure that user specified on the configuration file.<br> \n",
    "The value of _R_ represents the performance of a particular configuration (higher value means better performing configuration). We used Ranking Function _R_ below to calculate the rank scores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R =\\sum \\limits _{r=1} ^{d} \\frac{O_{dim} * (d-r)}{|Q| * (d-1)}, 0<R<=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d$         : total number of parameters (options) in a particular dimension<br>\n",
    "$O_{dim}$   : number of occurences of the dimension placed at rank $r$ (Rank 1, Rank 2, Rank 3, ...)<br>\n",
    "$|Q|$       : total number of queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAPyA.Rank.SDRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>class</i> Rank.<b>SDRank</b>(<i>config_path, log_path, ranking_sets, dimension</i>)\n",
    "<i>Parameters:</i> <br>\n",
    "&emsp; <b>config_path : str</b><br>\n",
    "&emsp;&emsp;<small>Specify the path to your configuration file(s). <i>i.e ./UIModule/settings_watdiv.yaml</small></i><br>\n",
    "&emsp;<b>log_path : str</b><br>\n",
    "&emsp;&emsp;<small>Specify the path to your log file(s). <i>i.e ./UI Module/log_watdiv</small></i><br>\n",
    "&emsp;<b>ranking_sets : str</b><br>\n",
    "&emsp;&emsp;<small>Ranking sets of user choice. <i>i.e dataset sizes (100M)</small></i><br>\n",
    "&emsp;<b>dimension : str</b><br>\n",
    "&emsp;&emsp;<small>A single dimension to be ranked. <i>i.e schemas</small></i><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class takes single dimension and dataset sizes as parameters that user specified inside their log files\n",
    "from Rank import SDRank\n",
    "\n",
    "schemaSDRank = SDRank(config_watdiv, logs_watdiv, '100M', 'schemas')\n",
    "partitionSDRank = SDRank(config_watdiv, logs_watdiv, '250M', 'partition')\n",
    "storageSDRank = SDRank(config_watdiv, logs_watdiv, '250M', 'storage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank.SDRank.calculateRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDRank.<b>calculateRank</b>(<i>*args</i>)\n",
    "<small>The function that automates calculating the rank scores of a single dimension using the Ranking Function above.</small><br><br>\n",
    "<small>Returns a table of configurations which is sorted based on the best performing configuration according to their Ranking Score along with number of occurences of the dimension being placed at the rank _r_ (1st, 2nd, 3rd, ...)</small><br><br>\n",
    "<i>Parameters:</i> <br>\n",
    "&emsp; <b>*args : str or list</b><br>\n",
    "&emsp;&emsp;<small>This method takes an arbitrary number of parameters of strings and lists.<br>\n",
    "&emsp;&emsp;&ensp;str -> slice the table according to string input. <i>i.e. \"predicate\" will slice the table by the <b>predicate</b> partitioning</i><br>\n",
    "&emsp;&emsp;&ensp;list -> remove some queries out of the ranking calculations. <i>i.e [7,8,9] will remove query <b>7, 8,and 9</b> from the calculation</small></i><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single dimension ranking by storage without excluding queries\n",
    "storageSDRank.calculateRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single dimension ranking by storage excluding query 7,8,and 9\n",
    "excludeQuery = [7,8,9]\n",
    "storageSDRank.calculateRank(excludeQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing partition single dimension ranking by predicate partitioning\n",
    "partitionSDRank.calculateRank('horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing schema single dimension ranking by predicate partitioning and csv storage format while excluding some queries\n",
    "schemasSDRank.calculateRank('predicate', 'csv', [3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank.SDRank.plotRadar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDRank.<b>plotRadar</b>()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>Ranking over one dimension is insufficient when it counts multiple dimensions. The presence of trade-offs reduces the accuracy of single dimension ranking functions which could be seen in the radar plot below.</small><br><br>\n",
    "<small>This method returns a radar chart that shows the presence of trade-offs by using the single dimension ranking criterion that reduces the accuracy of the other dimensions</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example shows a figure of the top configuration of ranking by schema is optimized towards its dimension only, ignoring the other two dimension.\n",
    "from Rank import SDRank\n",
    "SDRank(config_watdiv, logs_watdiv, '100M', 'schemas').plotRadar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to radar plot, PAPyA also provides visualization that shows the performance of a single dimension parameters that user can choose in terms of their rank scores<br>\n",
    "This <b>plot</b> method takes a single argument which is the view projection option that user can specify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema SD Ranks pivoting Storage formats for Predicate Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Rank import SDRank\n",
    "# example of schema dimension plots\n",
    "config = \"settings.yaml\"\n",
    "logs = \"log\"\n",
    "\n",
    "SDRank(config, logs, '100M', 'schemas').plot('predicate')\n",
    "SDRank(config, logs, '100M', 'storage').plot('st')\n",
    "SDRank(config, logs, '100M', 'partition').plot('csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"settings_watdiv.yaml\" # config file location\n",
    "logs = \"log_watdiv\" # logs file location\n",
    "\n",
    "from Rank import SDRank\n",
    "\n",
    "queries = ['Q11', 'Q14']\n",
    "schemaSDRank = SDRank(config, logs, '100M', 'schemas').plotBox(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of MDRank class with 100M dataset size as ranking set of the experiment\n",
    "from Rank import MDRank\n",
    "\n",
    "config = \"settings_watdiv.yaml\"\n",
    "logs = \"log_watdiv\"\n",
    "\n",
    "multiDimensionRank = MDRank(config, logs, '250M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the top 5 configurations according to paretoQ method sorted from best to worst\n",
    "multiDimensionRank.paretoQ().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the top 5 configurations according to paretoAgg method sorted from best to worst\n",
    "multiDimensionRank.paretoAgg().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>plot</b> method shows the solutions for _paretoAgg_ as shades of green areas projected in a three dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiDimensionRank.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both conformance and coherence classes takes a list of ranking criterion that the user can specify\n",
    "from Ranker import Conformance, Coherence\n",
    "\n",
    "config = 'settings_watdiv.yaml'\n",
    "logs = 'log_watdiv'\n",
    "\n",
    "conformance_set = ['schemas', 'partition', 'storage', 'paretoQ', 'paretoAgg']\n",
    "coherence_set = ['schemas', 'partition', 'storage', 'paretoQ', 'paretoAgg']\n",
    "\n",
    "conf = Conformance(config, logs, '100M', conformance_set, 5, 28)\n",
    "coh = Coherence(config, logs,coherence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.configurationQueryRanks(dimension = 'paretoAgg', mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh.run('250M', '500M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only takes single dimensions\n",
    "coh.heatMap('100M', \"500M\", dimension='paretoQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh.heatMapSubtract('100M', '250M', '500M', dimension='paretoQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ahpy\n",
    "\n",
    "query_comparison = {('Q1', 'Q2'): 1/7, ('Q1', 'Q3'): 1, ('Q1', 'Q4'): 1/9, ('Q1', 'Q5'): 1/3,\n",
    "                    ('Q1', 'Q6'): 1/5, ('Q1', 'Q7'): 1/7, ('Q1', 'Q8'): 1/9, ('Q1', 'Q9'): 1/3, ('Q1', 'Q10'): 1, ('Q1', 'Q11'): 1,\n",
    "                    ('Q2', 'Q3'): 7, ('Q2', 'Q4'): 1/9, ('Q2', 'Q5'): 3,\n",
    "                    ('Q2', 'Q6'): 5, ('Q2', 'Q7'): 1, ('Q2', 'Q8'): 1/9, ('Q2', 'Q9'): 3, ('Q2', 'Q10'): 7, ('Q2', 'Q11'): 7,\n",
    "                    ('Q3', 'Q4'): 1/9, ('Q3', 'Q5'): 1/3,\n",
    "                    ('Q3', 'Q6'): 1/5, ('Q3', 'Q7'): 1/7, ('Q3', 'Q8'): 1/9, ('Q3', 'Q9'): 1/3, ('Q3', 'Q10'): 1, ('Q3', 'Q11'): 1,\n",
    "                    ('Q4', 'Q5'): 3,\n",
    "                    ('Q4', 'Q6'): 5, ('Q4', 'Q7'): 7, ('Q4', 'Q8'): 1, ('Q4', 'Q9'): 3, ('Q4', 'Q10'): 9, ('Q4', 'Q11'): 9,\n",
    "                    ('Q5', 'Q6'): 1/5, ('Q5', 'Q7'): 1/7, ('Q5', 'Q8'): 1/9, ('Q5', 'Q9'): 1, ('Q5', 'Q10'): 3, ('Q5', 'Q11'): 3,\n",
    "                    ('Q6', 'Q7'): 1/7, ('Q6', 'Q8'): 1/9, ('Q6', 'Q9'): 3, ('Q6', 'Q10'): 5, ('Q6', 'Q11'): 5,\n",
    "                    ('Q7', 'Q8'): 1/9, ('Q7', 'Q9'): 3, ('Q7', 'Q10'): 7, ('Q7', 'Q11'): 7,\n",
    "                    ('Q8', 'Q9'): 3, ('Q8', 'Q10'): 9, ('Q8', 'Q11'): 9,\n",
    "                    ('Q9', 'Q10'): 3, ('Q9', 'Q11'): 3,\n",
    "                    ('Q10', 'Q11'): 1,}\n",
    "\n",
    "queries = ahpy.Compare(name='Queries', comparisons=query_comparison, precision=3, random_index='saaty')\n",
    "\n",
    "print(queries.target_weights)\n",
    "\n",
    "print(queries.consistency_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('RDF_BenchRankingLib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e41b15c1429a098af195db8ddc7e23165af5d7884fc53e33c8379c749ff89684"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
